# 20150617工作计划
前一阶段实习工作总结与未来工作回顾

## 将ngram融入矩阵分解框架
基于Spark ALS， 将ngram作为矩阵分解的基本单元， 预测ngram的分数，然后重新将ngram分数融入到sentence分数的预测中，在一个月预测一周， 一个月预测三天的任务中都比原方案的sentence分数预测效果更好。

## 矩阵分解和图计算框架
[矩阵分解和图计算框架](http://dataunion.org/3111.html)

- 问题基本假设
1. 评分矩阵$R_{u,i}$ , 我们认为存在一个K维的隐空间，用户偏好矩阵P：$m*k$ ; 物品偏好矩阵Q: $k*n$; P的每一行表示用户U在K维隐空间上的偏好， Q的每一列表示的是物品i在K维空间上的特性。第u个用户的偏好可以记作p_u，是一个$1*K$的Vector， 而第i个句子的偏好记作q_i,是一个$K*1$的Vector，那么用户对于物品i的打分预估值就是$p_u * q_i$

所以loss function可以定义为：
$$L=\sum_{(u,i)}[(R_{u,i}-p_u*q_i)^2 + \lambda(\|p_u\||_2 + \|q_i\|_2) ] $$
